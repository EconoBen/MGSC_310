{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1EIDvTq3MulGe5c42ANE-F8stQvXTZycG","authorship_tag":"ABX9TyPGH/fA6S6g8Bk1y9+BNk2S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Student and Problem Set Info\n","---\n","\n","\n","## Title: MGSC 310: Problem Set 1\n","\n","Author:\n","\n","Ben Labaschin, King of the Notebooks, Destroyer of Worlds.\n"],"metadata":{"id":"iGTMJcjlG6-Y"}},{"cell_type":"markdown","source":["# Libraries"],"metadata":{"id":"WHmMHbO3JUTa"}},{"cell_type":"code","source":["from os import environ\n","from google.colab import drive"],"metadata":{"id":"qpI2l1jLJTlv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"LuN6N1mjJXo7"}},{"cell_type":"code","source":["# Ensure you run this cell or otherwise connect to your Google Drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8QJWfb8JW-0","executionInfo":{"status":"ok","timestamp":1694391394313,"user_tz":420,"elapsed":23218,"user":{"displayName":"Ben Labaschin","userId":"07831406811640108386"}},"outputId":"f1f95ffe-d74c-4500-e886-7636db19f741"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Question 1, Training and Testing Datasets\n","\n","a) Load the IMDB_movies dataset. Use pandas to create columns `grossM` and `budgetM` that are budget and gross respectively in units of 1 Million.\n","\n","Also, separately, create two new columns: `log_gross` and `log_budget` that are equal to the natural log of `gross` and `budget`.\n","\n","Store ([copy](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)) the new DataFrame as `movies_clean`.\n","\n","**Hint: import the `log` function from the `numpy` library**"],"metadata":{"id":"msP9R1t9JibX"}},{"cell_type":"markdown","source":["b) Use pandas to create a new column called `rating_simple`, using `content_rating` as its source, that explicitly lists the four most common values and the rest are given the category \"Other\". Add this new column to the `movies_clean` DataFrame.\n","\n","Strategy if it were me: To get the most common values, use the `.value_counts()` function, more [here](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html). Grab the four most common categories and assign them to a list. Then use an `.apply` lambda to assign any categories _not_ in that list to the variable `Other`."],"metadata":{"id":"BVu45VctmhXs"}},{"cell_type":"markdown","source":["c) Use the `crosstab()` function from Pandas (more [here](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html))\n","to compare `content_rating` and `rating_simple`. In your own words, what does crosstab do?\n","\n","**Hint: `from pandas import crosstab`**"],"metadata":{"id":"kRrN88yenuuY"}},{"cell_type":"markdown","source":["d) Sometimes we want to convert text data into numerical representations. Look at the get_dummies function from pandas [here](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html).\n","\n","Apply `.get_dummies()` to the following columns: 'country', 'language', 'director_name'. What happens when you run the code?\n","\n","Save the new dataframe as `dummy_movies`"],"metadata":{"id":"vBpkdYrzo6Ic"}},{"cell_type":"markdown","source":["e) Use train_test_split from sklearn to split the `dummy_movies` dataset into training and testing sets of 80% and 20% each respectively.\n","\n","The feature dataset should contain all columns that aren't `grossM`\n","The target dataset should contain `grossM`.\n","\n","**Hint: try [`.drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n","\n","Call these dataframes X_train, y_train, X_test, and y_test."],"metadata":{"id":"ibUAHawHoTuN"}},{"cell_type":"markdown","source":["f) In your own words, explain the purpose of the training dataset."],"metadata":{"id":"6e7U2SmHq5JY"}},{"cell_type":"markdown","source":["g) In your own words, explain the purpose of the test dataset"],"metadata":{"id":"jdlOWsnmq_1z"}},{"cell_type":"markdown","source":["# Question 2, Predicting Movie Gross\n","a) Using the `movies_clean` DataFrame, estimate an OLS (using statsmodels.api) regression model where `imdb_score` is the dependent variable and `grossM` is the independent variable. Store this model as `model`."],"metadata":{"id":"3t-4ELXDrPY8"}},{"cell_type":"markdown","source":["b) Interpret the coefficient for `imdb_score` reletive to `grossM`, being specific about the magnitude of the impact of the variable on gross, and the direction (positive or negative)."],"metadata":{"id":"FcArbxafsg4F"}},{"cell_type":"markdown","source":["c) Discuss the significance of the coefficient for imdb_score. What does this imply about the relationship between imdb_score and gross?"],"metadata":{"id":"-BhFWUJbtx7w"}}]}